{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports #",
   "id": "1ad4492988504285"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T15:54:14.174027Z",
     "start_time": "2025-06-05T15:54:14.152520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import copy\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from torchvision.ops import sigmoid_focal_loss\n",
    "from Numeric-Features-model.MLPClassifier import MLPClassifier\n"
   ],
   "id": "7d495a44f3e586da",
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (781908333.py, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[6], line 13\u001B[1;36m\u001B[0m\n\u001B[1;33m    from Numeric-Features-model.MLPClassifier import MLPClassifier\u001B[0m\n\u001B[1;37m                ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Functions #",
   "id": "babc510f775cc61e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:15:19.686356Z",
     "start_time": "2025-06-05T14:15:19.622742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === Convert to Torch Tensors ===\n",
    "def to_tensor(x, y):\n",
    "    return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def find_best_threshold(model, val_loader, device='cuda',beta=0.6):\n",
    "    model.eval()\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            logits = model(X_batch)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    all_probs = np.array(all_probs)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    thresholds = np.linspace(0.35, 0.99, 99)\n",
    "    best_score = -np.inf\n",
    "    best_threshold = 0.5\n",
    "\n",
    "    for t in thresholds:\n",
    "        preds = (all_probs > t).astype(int)\n",
    "        tp = np.sum((preds == 1) & (all_labels == 1))\n",
    "        fp = np.sum((preds == 1) & (all_labels == 0))\n",
    "        fn = np.sum((preds == 0) & (all_labels == 1))\n",
    "\n",
    "        precision = tp / (tp + fp + 1e-9)\n",
    "        recall = tp / (tp + fn + 1e-9)\n",
    "        score = beta * precision + (1 - beta) * recall  # Custom blend\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = t\n",
    "\n",
    "    print(f\"âœ… Best Threshold: {best_threshold:.3f} with Precision-Recall Weighted Score: {best_score:.4f}\")\n",
    "    return best_threshold\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Training Function ===\n",
    "def train_model(model, train_loader, val_loader,\n",
    "                device='cuda',\n",
    "                max_epochs=500,\n",
    "                patience=10,\n",
    "                learning_rate=0.001,\n",
    "                weight_decay=1e-5,\n",
    "                focal_alpha=0.5,\n",
    "                focal_gamma=2.0):\n",
    "    # Loss and optimizer\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(\n",
    "        model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.to(device)\n",
    "    best_model = None\n",
    "    best_val_loss = float('inf')\n",
    "    no_improve_epochs = 0\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(X_batch)\n",
    "            loss = sigmoid_focal_loss(\n",
    "                inputs=logits,\n",
    "                targets=y_batch,\n",
    "                alpha=focal_alpha,\n",
    "                gamma=focal_gamma,\n",
    "                reduction='mean'\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in val_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "                val_logits = model(X_val)\n",
    "                val_loss = sigmoid_focal_loss(\n",
    "                    inputs=val_logits,\n",
    "                    targets=y_val,\n",
    "                    alpha=focal_alpha,\n",
    "                    gamma=focal_gamma,\n",
    "                    reduction='mean'\n",
    "                )\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{max_epochs} - Val Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss.item() < best_val_loss - 1e-4:\n",
    "            best_val_loss = val_loss.item()\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            no_improve_epochs = 0\n",
    "        else:\n",
    "            no_improve_epochs += 1\n",
    "            if no_improve_epochs >= patience:\n",
    "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "                break\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, data_loader, device='cuda', threshold=0.5, plot_roc=True, label=\"Test\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_logits = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in data_loader:\n",
    "            X_batch = X_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            logits = model(X_batch)\n",
    "            probs = torch.sigmoid(logits)\n",
    "\n",
    "            all_logits.append(logits.cpu())\n",
    "            all_preds.append(probs.cpu())\n",
    "            all_labels.append(y_batch.cpu())\n",
    "\n",
    "    # Concatenate batches\n",
    "    y_true = torch.cat(all_labels).numpy()\n",
    "    y_probs = torch.cat(all_preds).numpy()\n",
    "    y_logits = torch.cat(all_logits).numpy()\n",
    "    y_pred = (y_probs > threshold).astype(int)\n",
    "\n",
    "    # === Metrics ===\n",
    "    from sklearn.metrics import (\n",
    "        confusion_matrix, classification_report,\n",
    "        roc_auc_score, roc_curve, log_loss\n",
    "    )\n",
    "\n",
    "    print(f\"\\nðŸ“Š Evaluation on: {label}\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred, digits=4))\n",
    "\n",
    "    roc_auc = roc_auc_score(y_true, y_probs)\n",
    "    print(f\"ROC AUC Score: {roc_auc:.4f}\")\n",
    "\n",
    "    # === Loss & Generalization Error ===\n",
    "    bce_loss = nn.BCEWithLogitsLoss()\n",
    "    logits_tensor = torch.tensor(y_logits, dtype=torch.float32)\n",
    "    targets_tensor = torch.tensor(y_true, dtype=torch.float32)\n",
    "    loss = bce_loss(logits_tensor, targets_tensor).item()\n",
    "    print(f\"{label} BCE Loss: {loss:.6f}\")\n",
    "\n",
    "    return loss"
   ],
   "id": "13a1737099c1408e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data games #",
   "id": "6d4a0d6aeac97ecd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:15:20.050844Z",
     "start_time": "2025-06-05T14:15:19.753660Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Separate features and labels\n",
    "df = pd.read_csv(\"../data/labeled_intersection.csv\")\n",
    "\n",
    "X = df.drop(columns=['userid', 'label']).values\n",
    "y = df['label'].values\n",
    "\n",
    "# === Scale Features ===\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# === Split the Data ===\n",
    "SEED = 42\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, stratify=y, random_state=SEED # stratify ensures same proportion class balance in splits\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=SEED\n",
    ")\n",
    "\n",
    "original_counts = Counter(y_train)  # This is before SMOTE\n",
    "num_neg = original_counts[0]\n",
    "num_pos = original_counts[1]\n",
    "pos_weight = torch.tensor([num_neg / num_pos], dtype=torch.float32)\n",
    "print(f\"Using pos_weight: {pos_weight.item():.4f}\")\n",
    "\n",
    "# === Apply SMOTE *only* on training set ===\n",
    "smote = SMOTE(random_state=SEED)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n"
   ],
   "id": "42b90e7049a38f0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pos_weight: 3.1111\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tensors ##",
   "id": "3714cd9425c99b29"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:15:20.265479Z",
     "start_time": "2025-06-05T14:15:20.230628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === Convert df's to Tensors ===\n",
    "X_train_tensor, y_train_tensor = to_tensor(X_train_resampled, y_train_resampled)\n",
    "X_val_tensor, y_val_tensor = to_tensor(X_val, y_val)\n",
    "X_test_tensor, y_test_tensor = to_tensor(X_test, y_test)\n",
    "\n",
    "# === TensorDatasets ===\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# === DataLoaders ===\n",
    "USE_FULL_BATCH = False  # Change to True if you want 1-batch training\n",
    "\n",
    "BATCH_SIZE = (\n",
    "    len(train_dataset) if USE_FULL_BATCH else 128\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)"
   ],
   "id": "dfa88874ad1e1183",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Model training #",
   "id": "b89be86a5eb4366c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:17:09.161435Z",
     "start_time": "2025-06-05T14:15:20.439327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MLPClassifier(input_dim=X_train_tensor.shape[1])\n",
    "trained_model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    focal_alpha=0.5\n",
    ")\n",
    "best_threshold = find_best_threshold(trained_model, val_loader, beta=0.5)\n",
    "\n",
    "train_loss = evaluate_model(trained_model, train_loader,threshold=best_threshold, device='cuda', label=\"Train\")\n",
    "test_loss = evaluate_model(trained_model, test_loader, threshold=best_threshold, device='cuda', label=\"Test\")\n",
    "\n",
    "print(f\"\\nðŸ§  Generalization Gap (|Train - Test|): {abs(train_loss - test_loss):.6f}\")\n"
   ],
   "id": "d3d7923e4a4df842",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500 - Val Loss: 0.0595\n",
      "Epoch 2/500 - Val Loss: 0.0597\n",
      "Epoch 3/500 - Val Loss: 0.0572\n",
      "Epoch 4/500 - Val Loss: 0.0587\n",
      "Epoch 5/500 - Val Loss: 0.0563\n",
      "Epoch 6/500 - Val Loss: 0.0553\n",
      "Epoch 7/500 - Val Loss: 0.0584\n",
      "Epoch 8/500 - Val Loss: 0.0528\n",
      "Epoch 9/500 - Val Loss: 0.0552\n",
      "Epoch 10/500 - Val Loss: 0.0556\n",
      "Epoch 11/500 - Val Loss: 0.0562\n",
      "Epoch 12/500 - Val Loss: 0.0540\n",
      "Epoch 13/500 - Val Loss: 0.0551\n",
      "Epoch 14/500 - Val Loss: 0.0542\n",
      "Epoch 15/500 - Val Loss: 0.0557\n",
      "Epoch 16/500 - Val Loss: 0.0552\n",
      "Epoch 17/500 - Val Loss: 0.0547\n",
      "Epoch 18/500 - Val Loss: 0.0572\n",
      "Early stopping triggered at epoch 18\n",
      "âœ… Best Threshold: 0.487 with Precision-Recall Weighted Score: 0.6972\n",
      "\n",
      "ðŸ“Š Evaluation on: Train\n",
      "Confusion Matrix:\n",
      "[[60055  8440]\n",
      " [18047 50448]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7689    0.8768    0.8193     68495\n",
      "         1.0     0.8567    0.7365    0.7921     68495\n",
      "\n",
      "    accuracy                         0.8067    136990\n",
      "   macro avg     0.8128    0.8067    0.8057    136990\n",
      "weighted avg     0.8128    0.8067    0.8057    136990\n",
      "\n",
      "ROC AUC Score: 0.8860\n",
      "Train BCE Loss: 0.526708\n",
      "\n",
      "ðŸ“Š Evaluation on: Test\n",
      "Confusion Matrix:\n",
      "[[12816  1862]\n",
      " [ 1197  3521]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9146    0.8731    0.8934     14678\n",
      "         1.0     0.6541    0.7463    0.6972      4718\n",
      "\n",
      "    accuracy                         0.8423     19396\n",
      "   macro avg     0.7843    0.8097    0.7953     19396\n",
      "weighted avg     0.8512    0.8423    0.8457     19396\n",
      "\n",
      "ROC AUC Score: 0.8865\n",
      "Test BCE Loss: 0.514415\n",
      "\n",
      "ðŸ§  Generalization Gap (|Train - Test|): 0.012293\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Save model #",
   "id": "dd88ecfdab378862"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T14:36:56.776929Z",
     "start_time": "2025-06-05T14:36:56.761176Z"
    }
   },
   "cell_type": "code",
   "source": "torch.save(model.state_dict(), \"trained-model/mlp_model.pt\")\n",
   "id": "220dbf4ec0022379",
   "outputs": [],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
